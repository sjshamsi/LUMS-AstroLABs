{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Astronomical Data AnalysisÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package ```tensorflow``` is not included by default in most Python distributions. \n",
    "If you use Anaconda, see [docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/](https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/) for an installation guide. Other options are explained here: [www.tensorflow.org/install](https://www.tensorflow.org/install)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data file ``efigi.dat`` loaded below is a pre-selected subset of the [EFIGI survey dataset](https://www.astromatic.net/projects/efigi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"data_files/galaxies/efigi.dat\",\"r\")\n",
    "\n",
    "names = []\n",
    "types = []\n",
    "\n",
    "for line in data:\n",
    "    fields = line.split(\" \")\n",
    "    names.append( fields[0] )\n",
    "    types.append( fields[1] )\n",
    "    \n",
    "nData = len(names)\n",
    "imgSize = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elliptical galaxies belong to class 0, spirals to class 1 and irregulars to class 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = np.zeros((nData,imgSize,imgSize,3))\n",
    "labels = np.zeros(nData, dtype='int')\n",
    "\n",
    "for i in range(nData):\n",
    "    # load image\n",
    "    img = image.open(\"data_files/galaxies/png/\"+str(names[i])+\".png\")\n",
    "\n",
    "    # resize to imgSize\n",
    "    imgResized = img.resize(size=(imgSize,imgSize))\n",
    "    \n",
    "    galaxies[i,:,:,:] = np.array(imgResized)/255\n",
    "    labels[i] = types[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the full dataset into training, validation, and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = labels.size\n",
    "sample = random.sample([n for n in range(size)], int(0.3*size))\n",
    "\n",
    "# split in training and other set\n",
    "otherLabels = labels[sample]\n",
    "otherGalaxies = galaxies[sample,:,:,:]\n",
    "trainLabels = np.delete(labels, sample)\n",
    "trainGalaxies = np.delete(galaxies, sample, axis=0)\n",
    "\n",
    "print(otherLabels.size, trainLabels.size)\n",
    "print(otherGalaxies.shape, trainGalaxies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = otherLabels.size\n",
    "subsample = random.sample([n for n in range(size)], int(size/2))\n",
    "\n",
    "# split into validation and test sets\n",
    "valdLabels = otherLabels[subsample]\n",
    "valdGalaxies = otherGalaxies[subsample,:,:,:]\n",
    "testLabels = np.delete(otherLabels, subsample)\n",
    "testGalaxies = np.delete(otherGalaxies, subsample, axis=0)\n",
    "\n",
    "print(valdLabels.size, testLabels.size)\n",
    "print(valdGalaxies.shape, testGalaxies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(trainLabels, bins=[-0.5,0.5,1.5,2.5], histtype='step', lw=2)\n",
    "plt.hist(valdLabels,  bins=[-0.5,0.5,1.5,2.5], histtype='step', lw=2, ls='--')\n",
    "plt.hist(testLabels,  bins=[-0.5,0.5,1.5,2.5], histtype='step', lw=2, ls=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galNet = keras.Sequential([\n",
    "    keras.layers.Conv2D(96, (8,8), activation='relu', \n",
    "                        input_shape=(imgSize,imgSize,3)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galNet.compile(optimizer='adam', \n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = galNet.fit(trainGalaxies, trainLabels, epochs = 40, \n",
    "                     validation_data=(valdGalaxies, valdLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training vs validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4), dpi=100)\n",
    "\n",
    "plt.plot(results.history['loss'], color='green', label='training')\n",
    "plt.plot(results.history['val_loss'], color='red', label='validation')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"galnet_loss.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{results.history['accuracy'][-1]:.4f} \"\n",
    "      f\"{results.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified network (smaller number of feature maps, dropout layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galNet = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (8,8), activation='relu', \n",
    "                        input_shape=(imgSize,imgSize,3)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galNet.compile(optimizer='adam', \n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = galNet.fit(trainGalaxies, trainLabels, epochs = 40, \n",
    "                     validation_data=(valdGalaxies, valdLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training vs validation data (modified network):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4), dpi=100)\n",
    "\n",
    "plt.plot(results.history['loss'], color='green', label='training')\n",
    "plt.plot(results.history['val_loss'], color='red', label='validation')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"galnet_loss2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4), dpi=100)\n",
    "\n",
    "plt.plot(results.history['accuracy'], color='green', label='training')\n",
    "plt.plot(results.history['val_accuracy'], color='red', label='validation')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{results.history['accuracy'][-1]:.4f} \"\n",
    "      f\"{results.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = galNet.evaluate(testGalaxies, testLabels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification of a galaxy (NGC 1232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.open(\"data_files/galaxies/NGC_1232.jpg\")\n",
    "\n",
    "imgResized = img.resize(size=(imgSize,imgSize))\n",
    "\n",
    "imgArr = np.array(imgResized)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgArrExp = np.expand_dims(imgArr, axis=0)\n",
    "print(imgArrExp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = galNet.predict(imgArrExp)\n",
    "\n",
    "label = [\"elliptical\", \"spiral\", \"irregular\"]\n",
    "for i,p in enumerate(pred.flatten()):\n",
    "    print(f\"{label[i]:10s} {p:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the data\n",
    "\n",
    "Load dataset (not included in zip archive; can be requested from authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/hs/fs06/data/AG_Schmidt/specnet/training\"\n",
    "#path = \"specnet/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specnames = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "n_spectra = len(specnames)\n",
    "print(\"Total number of training spectra:\", n_spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine labels from filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros(n_spectra, dtype='int')\n",
    "\n",
    "for i,spec in enumerate(specnames):\n",
    "    temp[i] = int( spec[0:4] )\n",
    "    \n",
    "temp_class = sorted(list(set(temp)))\n",
    "n_labels = len(temp_class)\n",
    "\n",
    "print(\"Total number of temperature classes:\", len(temp_class))\n",
    "print(\"List of temperatures:\", temp_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_file = join(path, \"5800_1_65999_177.97.npz\") \n",
    "\n",
    "spec_arr = np.load(spectrum_file)\n",
    "print(spec_arr.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = spec_arr[\"arr_0\"][:,0]\n",
    "flux = spec_arr[\"arr_0\"][:,1]\n",
    "\n",
    "print(\"Wavelength range:\", np.min(wave), np.max(wave))\n",
    "\n",
    "spec_size = len(flux)\n",
    "\n",
    "print(\"Number of values per spectrum:\", spec_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "plt.plot(0.1*wave, flux, color='navy')\n",
    "plt.xlabel(\"$\\lambda$ / nm\")\n",
    "plt.xlim(650,660)\n",
    "plt.ylabel(\"Normalized flux\")\n",
    "plt.ylim(0,1.05)\n",
    "\n",
    "plt.savefig(\"synth_spect.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 20\n",
    "channel_length = int(spec_size/n_channels)\n",
    "\n",
    "print(\"Values per channel:\", channel_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training data array (this may take quite a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = np.zeros((n_spectra, channel_length, n_channels), \n",
    "                   dtype='float64')\n",
    "labels = np.zeros(n_spectra, dtype='int')\n",
    "\n",
    "for i in range(n_spectra):\n",
    "    labels[i] = temp_class.index(temp[i])\n",
    "    \n",
    "    spectrum_file = join(path, specnames[i])\n",
    "    spec_arr = np.load(spectrum_file)\n",
    "\n",
    "    flux = spec_arr[\"arr_0\"][:,1]\n",
    "    flux_2d = np.reshape(flux, (-1,n_channels))\n",
    "    \n",
    "    spectra[i,:,:] = flux_2d\n",
    "    \n",
    "print(spectra.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpecNet = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(24, 4, activation='relu', input_shape=(channel_length, n_channels)),\n",
    "    tf.keras.layers.Conv1D(120, 10, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(n_labels, activation='softmax'),\n",
    "])\n",
    "\n",
    "print(SpecNet.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpecNet.compile(optimizer='adam', \n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpecNet.fit(spectra, labels, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following statement for GPU offloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    SpecNet.fit(spectra, labels, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/hs/fs06/data/AG_Schmidt/specnet/test\"\n",
    "specnames_test = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    \n",
    "n_spectra_test = len(specnames_test)\n",
    "\n",
    "print(\"Total number of test spectra:\", n_spectra_test)\n",
    "\n",
    "temp_test = np.zeros(n_spectra_test, dtype='int')\n",
    "i = 0\n",
    "\n",
    "for spec in specnames_test:\n",
    "    temp_test[i] = int( spec[0:4] )\n",
    "    i=i+1\n",
    "    \n",
    "spectra_test = np.zeros((n_spectra_test,channel_length, n_channels), dtype='float64')\n",
    "labels_test = np.zeros(n_spectra_test, dtype='int')\n",
    "\n",
    "for i in range(n_spectra_test):\n",
    "    labels_test[i] = temp_class.index(temp_test[i])\n",
    "    \n",
    "for i in range(n_spectra_test):\n",
    "    spectrum_file = join(path, specnames_test[i])\n",
    "    spec_arr = np.load(spectrum_file)\n",
    "\n",
    "    flux = spec_arr[\"arr_0\"][:,1]\n",
    "    flux_2d = np.reshape(flux, (-1,n_channels))\n",
    "    \n",
    "    spectra_test[i,:,:] = flux_2d\n",
    "    \n",
    "print(spectra_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = SpecNet.evaluate(spectra_test, labels_test)\n",
    "print(\"Accuracy on the test data:\",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test of a single spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_test = 4000\n",
    "print(\"Name of the spectrum:\", specnames_test[i_test], \"\\n\")\n",
    "\n",
    "spec = spectra_test[i_test]\n",
    "\n",
    "guess = SpecNet.predict(np.expand_dims(spec, axis=0))\n",
    "\n",
    "for i in range(n_labels):\n",
    "    print(\"{:4d} K  {:6.2f} %\".\n",
    "          format(temp_class[i], 100*guess[0,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wave*0.1, spec.flatten(), color='navy')\n",
    "plt.xlabel(\"$\\lambda$ / nm\")\n",
    "plt.xlim(650,660)\n",
    "plt.ylabel(\"Normalized flux\")\n",
    "plt.ylim(0,1.05)\n",
    "\n",
    "plt.savefig(\"test_spect.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed format to tf since h5 results in an error for recent versions of ```h5py``` (see https://github.com/tensorflow/tensorflow/issues/44467)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpecNet.save('specnet_model.h5')\n",
    "SpecNet.save('data_files/specnet_model.tf',save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application to spectrum of the Sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore network from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpecNet = tf.keras.models.load_model('specnet_model.h5')\n",
    "SpecNet = tf.keras.models.load_model('data_files/specnet_model.tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need the following definitions if the training data were not processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_class = [4000, 4200, 4400, 4600, 4800, 5000, 5200, 5400, 5600, 5800, 6000]\n",
    "n_labels = len(temp_class)\n",
    "n_channels = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and plot spectrum of the Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_file = \"data_files/sun_spec.npz\"\n",
    "\n",
    "spec_arr = np.load(spectrum_file)\n",
    "wave = spec_arr[\"arr_0\"][:,0]\n",
    "flux = spec_arr[\"arr_0\"][:,1]\n",
    "\n",
    "flux_2d = np.reshape(flux, (-1,n_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wave*0.1, flux, color='navy')\n",
    "plt.xlabel(\"$\\lambda$ / nm\")\n",
    "plt.xlim(650,660)\n",
    "plt.ylabel(\"Normalized flux\")\n",
    "plt.ylim(0,1.05)\n",
    "\n",
    "plt.savefig(\"solar_spect.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = SpecNet.predict(np.expand_dims(flux_2d, axis=0))\n",
    "\n",
    "for i in range(n_labels):\n",
    "    print(\"{:4d} K  {:6.2f} %\".format(temp_class[i], 100*guess[0,i]))\n",
    "\n",
    "print(\"\\nEffective temperature estimate: {:.0f} K\".\n",
    "      format(np.average(temp_class, weights=guess.flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
